

root@csst-06:/home/ubuntu/laspdev# 
root@csst-06:/home/ubuntu/laspdev# python /home/ubuntu/laspdev/utility/setup_laspp.py d1
d1
ip:10.0.0.11
node:a
root@d1:/# [Kroot@d1:/# service vnstat start
[....] Starting vnStat daemon: vnstatd[?25l7[1G[[32m ok [39;49m8[?12l[?25h.
root@d1:/# vnstat -u -i d1-eth0
Error: Unable to read database "/var/lib/vnstat/d1-eth0": No such file or directory
Info: -> A new database has been created.
root@d1:/# vnstat -u
root@d1:/# vnstat

                      rx      /      tx      /     total    /   estimated
 eth0:
       Jun '20         4 KiB  /       1 KiB  /       5 KiB
       Jul '20         0 KiB  /       0 KiB  /       0 KiB  /       0 KiB
      06/26/20         4 KiB  /       1 KiB  /       5 KiB
         today         0 KiB  /       0 KiB  /       0 KiB  /      --    

 d1-eth0: Not enough data available yet.
root@d1:/# export PEER_SERVICE=partisan_hyparview_peer_service_manager
root@d1:/# export RATE_CLASS=c2
root@d1:/# export RATE_C1=10000
root@d1:/# export RATE_C2=40000
root@d1:/# export RATE_C3=70000
root@d1:/# export PROPAGATE_ON_UPDATE=false
root@d1:/# export MAX_ACTIVE_SIZE=50
root@d1:/# cd /opt/lasp
root@d1:/opt/lasp# epmd -daemon
root@d1:/opt/lasp# rebar3 shell --name a@10.0.0.11
[0;32m===> Verifying dependencies...
[0m[0;32m===> Compiling lasp
[0mErlang/OTP 19 [erts-8.3] [source] [64-bit] [smp:24:24] [ds:24:24:10] [async-threads:0] [hipe] [kernel-poll:false]

Eshell V8.3  (abort with ^G)
(a@10.0.0.11)1> [0;35m===> The rebar3 shell is a development tool; to deploy applications in production, consider using releases (http://www.rebar3.org/docs/releases)
[0m17:46:42.223 [info] Application lager started on node 'a@10.0.0.11'

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,sasl_safe_sup}
             started: [{pid,<0.253.0>},
                       {id,alarm_handler},
                       {mfargs,{alarm_handler,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,sasl_sup}
             started: [{pid,<0.252.0>},
                       {id,sasl_safe_sup},
                       {mfargs,
                           {supervisor,start_link,
                               [{local,sasl_safe_sup},sasl,safe]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,sasl_sup}
             started: [{pid,<0.254.0>},
                       {id,release_handler},
                       {mfargs,{release_handler,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,2000},
                       {child_type,worker}]

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
         application: sasl
          started_at: 'a@10.0.0.11'
17:46:42.253 [info] Application sasl started on node 'a@10.0.0.11'

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
         application: lasp_support
          started_at: 'a@10.0.0.11'
17:46:42.253 [info] Application lasp_support started on node 'a@10.0.0.11'

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
         application: acceptor_pool
          started_at: 'a@10.0.0.11'
17:46:42.253 [info] Application acceptor_pool started on node 'a@10.0.0.11'

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
         application: quickrand
          started_at: 'a@10.0.0.11'
17:46:42.254 [info] Application quickrand started on node 'a@10.0.0.11'

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
         application: uuid
          started_at: 'a@10.0.0.11'
17:46:42.254 [info] Application uuid started on node 'a@10.0.0.11'
17:46:42.258 [info] Using node name: 'a@10.0.0.11'
17:46:42.262 [info] Resolving "10.0.0.11"...

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.266.0>},
                       {id,timer_server},
                       {mfargs,{timer,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,1000},
                       {child_type,worker}]

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,inet_gethost_native_sup}
             started: [{pid,<0.268.0>},{mfa,{inet_gethost_native,init,[[]]}}]

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,kernel_safe_sup}
             started: [{pid,<0.267.0>},
                       {id,inet_gethost_native_sup},
                       {mfargs,{inet_gethost_native,start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]
17:46:42.263 [info] Resolved "a@10.0.0.11" to {10,0,0,11}
17:46:42.263 [info] Resolved "10.0.0.11" to {10,0,0,11}
17:46:42.317 [info] Partisan listening on {10,0,0,11}:44741 listen_addrs: [#{ip => {10,0,0,11},port => 44741}]

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,partisan_sup}
             started: [{pid,<0.313.0>},
                       {id,partisan_rpc_backend},
                       {mfargs,{partisan_rpc_backend,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,partisan_sup}
             started: [{pid,<0.314.0>},
                       {id,partisan_acknowledgement_backend},
                       {mfargs,
                           {partisan_acknowledgement_backend,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]
17:46:42.332 [info] Not using container orchestration; disabling.

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,partisan_sup}
             started: [{pid,<0.315.0>},
                       {id,partisan_orchestration_backend},
                       {mfargs,{partisan_orchestration_backend,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]
17:46:42.360 [info] node 'a@10.0.0.11' choosing random seed: {8440798,-576460749988343715,-576460752303423421}

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,partisan_sup}
             started: [{pid,<0.316.0>},
                       {id,partisan_hyparview_peer_service_manager},
                       {mfargs,
                           {partisan_hyparview_peer_service_manager,
                               start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,partisan_sup}
             started: [{pid,<0.317.0>},
                       {id,partisan_peer_service_events},
                       {mfargs,{partisan_peer_service_events,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]
17:46:42.363 [info] node 'a@10.0.0.11' choosing random seed: {8440798,-576460749988343715,-576460752303423421}

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,partisan_sup}
             started: [{pid,<0.318.0>},
                       {id,partisan_plumtree_backend},
                       {mfargs,{partisan_plumtree_backend,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,partisan_sup}
             started: [{pid,<0.319.0>},
                       {id,partisan_plumtree_broadcast},
                       {mfargs,{partisan_plumtree_broadcast,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,partisan_sup}
             started: [{pid,<0.320.0>},
                       {id,partisan_monitor},
                       {mfargs,{partisan_monitor,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,partisan_pool_sup}
             started: [{pid,<0.322.0>},
                       {id,partisan_pool},
                       {mfargs,{partisan_pool,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,partisan_pool_sup}
             started: [{pid,<0.323.0>},
                       {id,{partisan_socket,{10,0,0,11},44741}},
                       {mfargs,
                           {partisan_socket,start_link,[{10,0,0,11},44741]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,partisan_sup}
             started: [{pid,<0.321.0>},
                       {id,partisan_pool_sup},
                       {mfargs,{partisan_pool_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,20000},
                       {child_type,supervisor}]

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
         application: partisan
          started_at: 'a@10.0.0.11'
17:46:42.417 [info] Application partisan started on node 'a@10.0.0.11'

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,plumtree_sup}
             started: [{pid,<0.338.0>},
                       {id,plumtree_broadcast},
                       {mfargs,{plumtree_broadcast,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
         application: plumtree
          started_at: 'a@10.0.0.11'

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
         application: gen_fsm_compat
          started_at: 'a@10.0.0.11'
17:46:42.425 [info] Application plumtree started on node 'a@10.0.0.11'
17:46:42.426 [info] Application gen_fsm_compat started on node 'a@10.0.0.11'
17:46:42.428 [info] Setting jitter: false
17:46:42.431 [info] Setting jitter percent: 1
17:46:42.432 [info] Setting event interval: 0
17:46:42.432 [info] Setting max events: 1000
17:46:42.433 [info] Setting extended logging: false
17:46:42.434 [info] Setting mailbox logging: false
17:46:42.435 [info] Setting operation mode: delta_based
17:46:42.436 [info] Setting set type: orset
17:46:42.438 [info] Setting broadcast: false
17:46:42.462 [info] Membership: false
17:46:42.463 [info] Workflow: false
17:46:42.467 [info] AdClientEnabled: false
17:46:42.469 [info] AdServerEnabled: false
17:46:42.470 [info] TournClientEnabled: false
17:46:42.471 [info] TournServerEnabled: false
17:46:42.472 [info] ThroughputType: gset
17:46:42.473 [info] ThroughputClientEnabled: false
17:46:42.474 [info] ThroughputServerEnabled: false
17:46:42.474 [info] DivergenceType: gcounter
17:46:42.475 [info] DivergenceClientEnabled: false
17:46:42.476 [info] DivergenceServerEnabled: false

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,lasp_sup}
             started: [{pid,<0.385.0>},
                       {id,lasp_unique},
                       {mfargs,{lasp_unique,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,lasp_sup}
             started: [{pid,<0.386.0>},
                       {id,lasp_plumtree_backend},
                       {mfargs,{lasp_plumtree_backend,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,lasp_sup}
             started: [{pid,<0.387.0>},
                       {id,lasp_plumtree_memory_report},
                       {mfargs,{lasp_plumtree_memory_report,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,lasp_sup}
             started: [{pid,<0.388.0>},
                       {id,lasp_memory_utilization_report},
                       {mfargs,{lasp_memory_utilization_report,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]
17:46:42.511 [info] Backend initialized with pid: <0.393.0>
17:46:42.511 [info] Backend lasp_ets_storage_backend initialized: <0.393.0>

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,lasp_sup}
             started: [{pid,<0.389.0>},
                       {id,lasp_distribution_backend},
                       {mfargs,{lasp_distribution_backend,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]
17:46:42.520 [error] Rate Propagations c1: "10000" c2:"40000" c3:"70000" 

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
          supervisor: {local,lasp_sup}
             started: [{pid,<0.395.0>},
                       {id,lasp_process_sup},
                       {mfargs,{lasp_process_sup,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,infinity},
                       {child_type,supervisor}]

=PROGRESS REPORT==== 3-Jul-2020::17:46:42 ===
         application: lasp
          started_at: 'a@10.0.0.11'
[0;32m===> Booted types
[0m[0;32m===> Booted gen_flow
[0m[0;32m===> Booted syntax_tools
[0m[0;32m===> Booted compiler
[0m[0;32m===> Booted goldrush
[0m[0;32m===> Booted lager
[0m[0;32m===> Booted sasl
[0m[0;32m===> Booted lasp_support
[0m[0;32m===> Booted acceptor_pool
[0m[0;32m===> Booted quickrand
[0m[0;32m===> Booted uuid
[0m[0;32m===> Booted partisan
[0m[0;32m===> Booted plumtree
[0m[0;32m===> Booted gen_fsm_compat
[0m[0;32m===> Booted lasp
[0m17:46:42.520 [error] C1 propagation "2020-07-03T17:46:42.520" 
17:46:42.520 [error] C2 propagation "2020-07-03T17:46:42.520" 
17:46:42.520 [error] C3 propagation "2020-07-03T17:46:42.520" 
17:46:42.520 [error] batched message propagation "2020-07-03T17:46:42.520" 
17:46:42.522 [info] Application lasp started on node 'a@10.0.0.11'

(a@10.0.0.11)1> erlang:set_cookie(node(),'RPJVCXYDYULBNZFEFPHJ').
true
(a@10.0.0.11)2> application:get_env(partisan, max_active_size).
{ok,50}
(a@10.0.0.11)3> application:get_env(partisan, max_passive_size).
{ok,10}
(a@10.0.0.11)4> application:get_env(partisan, min_active_size).
{ok,9}
(a@10.0.0.11)5> partisan_config:set(passive_view_shuffle_period, 1000000000).
ok
(a@10.0.0.11)6> partisan_config:get(passive_view_shuffle_period).
1000000000
(a@10.0.0.11)7> )7> 17:46:52.521 [error] C1 propagation "2020-07-03T17:46:52.521" 
17:46:52.521 [error] Sending find_sub batch [] 
17:46:52.522 [error] Sending find_sub_aq batch [] 
17:46:52.522 [error] batched message propagation "2020-07-03T17:46:52.522" 
17:46:57.541 [error] Sending rate "c2" to 'a@11.0.0.11' 
17:47:02.522 [error] C1 propagation "2020-07-03T17:47:02.522" 
17:47:02.523 [error] Sending find_sub batch [] 
17:47:02.523 [error] Sending find_sub_aq batch [] 
17:47:02.523 [error] batched message propagation "2020-07-03T17:47:02.523" 
17:47:12.524 [error] C1 propagation "2020-07-03T17:47:12.524" 
17:47:12.524 [error] Sending find_sub batch [] 
17:47:12.524 [error] Sending find_sub_aq batch [] 
17:47:12.525 [error] batched message propagation "2020-07-03T17:47:12.525" 
17:47:22.522 [error] C2 propagation "2020-07-03T17:47:22.522" 
17:47:22.525 [error] C1 propagation "2020-07-03T17:47:22.525" 
17:47:22.541 [error] Sending find_sub batch [] 
17:47:22.541 [error] Sending find_sub_aq batch [] 
17:47:22.541 [error] batched message propagation "2020-07-03T17:47:22.541" 
17:47:32.527 [error] C1 propagation "2020-07-03T17:47:32.527" 
17:47:32.542 [error] Sending find_sub batch [] 
17:47:32.542 [error] Sending find_sub_aq batch [] 
17:47:32.542 [error] batched message propagation "2020-07-03T17:47:32.542" 
17:47:42.529 [error] C1 propagation "2020-07-03T17:47:42.529" 
17:47:42.543 [error] Sending find_sub batch [] 
17:47:42.543 [error] Sending find_sub_aq batch [] 
17:47:42.543 [error] batched message propagation "2020-07-03T17:47:42.543" 
17:47:52.522 [error] C3 propagation "2020-07-03T17:47:52.522" 
17:47:52.530 [error] C1 propagation "2020-07-03T17:47:52.530" 
17:47:52.545 [error] Sending find_sub batch [] 
17:47:52.545 [error] Sending find_sub_aq batch [] 
17:47:52.545 [error] batched message propagation "2020-07-03T17:47:52.545" 
17:48:02.524 [error] C2 propagation "2020-07-03T17:48:02.524" 
17:48:02.531 [error] C1 propagation "2020-07-03T17:48:02.531" 
17:48:02.547 [error] Sending find_sub batch [] 
17:48:02.547 [error] Sending find_sub_aq batch [] 
17:48:02.547 [error] batched message propagation "2020-07-03T17:48:02.547" 
17:48:02.598 [error] Sending rate "c2" to 'b@10.0.0.12' 
17:48:02.598 [error] Sending rate "c2" to 'c@10.0.0.13' 
17:48:02.598 [error] Sending Subscription to 'c@10.0.0.13' case1 
17:48:02.633 [error] Rate_subscribe_ack received from 'c@10.0.0.13' for rate "c2" 
17:48:05.636 [error] LASPVIN received find_sub Id: "c@11.0.0.13c1" From: 'a@11.0.0.11' Hop:2 
17:48:05.668 [error] Checking sub_exists for Id:"c@11.0.0.13c1" From:'a@11.0.0.11' Hop:2 
17:48:05.721 [error] Id is not get_connections(): ['a@11.0.0.11','b@10.0.0.12','c@10.0.0.13'] 
17:48:05.721 [error] LASPVIN found the peer at "2020-07-03T17:48:05.721" for ID: "c@11.0.0.13c1" ToNode: 'c@10.0.0.13' Via:'a@10.0.0.11' 
17:48:05.752 [error] LASPVINDEBUG Forwarding find_sub_aq for Id: "c@11.0.0.13c1" ToNode:'c@10.0.0.13' From:'a@10.0.0.11' to 'a@11.0.0.11' HopCount:1 
17:48:05.752 [error] Forwarding Req Id "c@11.0.0.13c1" to Peers RcvHop:2 IncHop:3 
17:48:05.785 [error] Forwarding ReqId "c@11.0.0.13c1" to Peer:'b@10.0.0.12' Hop:3 
17:48:05.785 [error] Forwarding ReqId "c@11.0.0.13c1" to Peer:'c@10.0.0.13' Hop:3 
17:48:11.060 [error] LASPVIN received find_sub Id: "c@10.0.0.13c1" From: 'c@10.0.0.13' Hop:1 
17:48:11.109 [error] Checking sub_exists for Id:"c@10.0.0.13c1" From:'c@10.0.0.13' Hop:1 
17:48:11.145 [error] Request Id "c@10.0.0.13c1" is from a Peer directly connected
17:48:11.145 [error] Forwarding Req Id "c@10.0.0.13c1" to Peers RcvHop:1 IncHop:2 
17:48:11.211 [error] Forwarding ReqId "c@10.0.0.13c1" to Peer:'b@10.0.0.12' Hop:2 
17:48:11.211 [error] LASPVIN Request forwarded~n
17:48:12.146 [error] LASPVIN received find_sub Id: "c@10.0.0.13c1" From: 'b@10.0.0.12' Hop:2 
17:48:12.171 [error] Checking sub_exists for Id:"c@10.0.0.13c1" From:'b@10.0.0.12' Hop:2 
17:48:12.196 [error] Hop 2 for Id "c@10.0.0.13c1" is more than existing 1...Skipping
17:48:12.196 [error] LASPVIN Request forwarded~n
17:48:12.532 [error] C1 propagation "2020-07-03T17:48:12.532" 
17:48:12.548 [error] Sending find_sub batch [{'a@10.0.0.11',"c1","c@11.0.0.13c1",3,'b@10.0.0.12'},{'a@10.0.0.11',"c1","c@11.0.0.13c1",3,'c@10.0.0.13'},{'a@10.0.0.11',"c1","c@10.0.0.13c1",2,'b@10.0.0.12'}] 
17:48:12.548 [error] Sent find_sub control message from batch 'a@10.0.0.11' "c1" "c@11.0.0.13c1" 3 'b@10.0.0.12' 
17:48:12.549 [error] Sent find_sub control message from batch 'a@10.0.0.11' "c1" "c@11.0.0.13c1" 3 'c@10.0.0.13' 
17:48:12.549 [error] Sent find_sub control message from batch 'a@10.0.0.11' "c1" "c@10.0.0.13c1" 2 'b@10.0.0.12' 
17:48:12.549 [error] Sending find_sub_aq batch [{"c@11.0.0.13c1",'c@10.0.0.13','a@10.0.0.11','a@10.0.0.11',1,'a@11.0.0.11'}] 
17:48:12.583 [error] Sent find_sub_aq control message for "c@11.0.0.13c1" ['c@10.0.0.13'] 'a@10.0.0.11' 'a@10.0.0.11' 1 'a@11.0.0.11' 
17:48:12.583 [error] batched message propagation "2020-07-03T17:48:12.583" 
17:48:15.738 [error] LASPVIN received find_sub_aq_lock for Id:"c@11.0.0.13c1" ToNode'c@10.0.0.13' From:'a@11.0.0.11' 
17:48:15.738 [error] LASPVIN updating rate ~n
17:48:15.738 [error] LASPVIN Locking reached chain end for Id:"c@11.0.0.13c1" Reveied from 'a@11.0.0.11' 
17:48:15.744 [error] Sending updated rate "c1" to 'a@11.0.0.11' 
17:48:15.744 [error] Sending updated rate "c1" to 'b@10.0.0.12' 
17:48:15.744 [error] Sending updated rate "c1" to 'c@10.0.0.13' 
17:48:15.745 [error] Received new rate from 'a@11.0.0.11' with new rate "c1"
17:48:15.745 [error] LASPVIN found the peer at "2020-07-03T17:48:15.745" for ID: "c@11.0.0.13c1" ToNode: 'a@11.0.0.11' Via:'a@10.0.0.11' 
17:48:15.745 [error] LASPVIN find_sub_aq Id exists not forwarding found_sub
17:48:15.745 [error] Sub_aq exists for Id:"c@11.0.0.13c1" but HopCount:1 is lower than existing hopcount:2 .. Forwarding request 
17:48:15.745 [error] LASPVIN found the peer at "2020-07-03T17:48:15.745" for ID: "c@10.0.0.13c1" ToNode: 'a@11.0.0.11' Via:'a@10.0.0.11' 
17:48:15.748 [error] LASPVINDEBUG Forwarding find_sub_aq for Id: "c@10.0.0.13c1" ToNode:'a@11.0.0.11' From:'a@10.0.0.11' to 'c@10.0.0.13' HopCount:1 
17:48:15.789 [error] LASPVIN found the peer at "2020-07-03T17:48:15.789" for ID: "c@11.0.0.13c1" ToNode: 'a@11.0.0.11' Via:'a@10.0.0.11' 
17:48:15.789 [error] LASPVIN find_sub_aq Id exists not forwarding found_sub
17:48:15.789 [error] Sub_aq exists for Id:"c@11.0.0.13c1" but HopCount:1 is lower than existing hopcount:2 .. Forwarding request 
17:48:15.789 [error] LASPVIN found the peer at "2020-07-03T17:48:15.789" for ID: "c@10.0.0.13c1" ToNode: 'a@11.0.0.11' Via:'a@10.0.0.11' 
17:48:15.789 [error] LASPVIN find_sub_aq Id exists not forwarding found_sub
17:48:15.789 [error] Sub_aq exists and Hop:1 > existing HopCount:1 
17:48:22.149 [error] LASPVIN received find_sub_aq for Id:"c@11.0.0.13c1" ToNodes:['c@10.0.0.13'] Via:'b@10.0.0.12' From:'b@10.0.0.12' HopCount:1 
17:48:22.150 [error] LASPVIN path ToNode: 'c@10.0.0.13' exists find_sub_aq:[[0]] 
17:48:22.150 [error] HopCount is more than existing, skipping.....
17:48:22.150 [error] LASPVIN received find_sub_aq for Id:"c@11.0.0.13c1" ToNodes:['a@10.0.0.11'] Via:'b@10.0.0.12' From:'b@10.0.0.12' HopCount:2 
17:48:22.150 [error] Discarding as I am the ToNode for Id "c@11.0.0.13c1" 
 
17:48:22.534 [error] C1 propagation "2020-07-03T17:48:22.534" 
17:48:22.584 [error] Sending find_sub batch [] 
17:48:22.584 [error] Sending find_sub_aq batch [{"c@10.0.0.13c1",'a@11.0.0.11','a@10.0.0.11','a@10.0.0.11',1,'c@10.0.0.13'},{"c@11.0.0.13c1",'a@11.0.0.11','a@10.0.0.11','a@10.0.0.11',2,'a@11.0.0.11'}] 
17:48:22.585 [error] Sent find_sub_aq control message for "c@10.0.0.13c1" ['a@11.0.0.11'] 'a@10.0.0.11' 'a@10.0.0.11' 1 'c@10.0.0.13' 
17:48:22.585 [error] Sent find_sub_aq control message for "c@11.0.0.13c1" ['a@11.0.0.11'] 'a@10.0.0.11' 'a@10.0.0.11' 2 'a@11.0.0.11' 
17:48:22.585 [error] batched message propagation "2020-07-03T17:48:22.585" 
17:48:25.754 [error] Received rate_subscribe from 'c@10.0.0.13' for rate "c1" 
17:48:25.755 [error] Received rate_subscribe from 'c@10.0.0.13' for rate "c1" 
17:48:25.756 [error] LASPVIN received find_sub_aq for Id:"c@11.0.0.13c1" ToNodes:['c@10.0.0.13'] Via:'c@10.0.0.13' From:'c@10.0.0.13' HopCount:1 
17:48:25.756 [error] LASPVIN path ToNode: 'c@10.0.0.13' exists find_sub_aq:[[0]] 
17:48:25.756 [error] HopCount is more than existing, skipping.....
17:48:25.756 [error] LASPVIN received find_sub_aq for Id:"c@11.0.0.13c1" ToNodes:['a@10.0.0.11'] Via:'c@10.0.0.13' From:'c@10.0.0.13' HopCount:2 
17:48:25.757 [error] Discarding as I am the ToNode for Id "c@11.0.0.13c1" 
 
17:48:32.536 [error] C1 propagation "2020-07-03T17:48:32.536" 
17:48:32.586 [error] Sending find_sub batch [] 
17:48:32.586 [error] Sending find_sub_aq batch [] 
17:48:32.586 [error] batched message propagation "2020-07-03T17:48:32.586" 
17:48:33.767 [warning] global: 'a@10.0.0.11' failed to connect to 'c@11.0.0.13'
17:48:35.766 [error] LASPVIN received find_sub_aq_lock for Id:"c@10.0.0.13c1" ToNode'a@11.0.0.11' From:'c@10.0.0.13' 
17:48:35.766 [error] LASPVIN Rate updated already ~n
17:48:35.766 [error] LASPVIN Locking reached chain end for Id:"c@10.0.0.13c1" Reveied from 'c@10.0.0.13' 
17:48:37.951 [warning] global: 'a@10.0.0.11' failed to connect to 'b@11.0.0.12'
17:48:42.526 [error] C2 propagation "2020-07-03T17:48:42.526" 
17:48:42.537 [error] C1 propagation "2020-07-03T17:48:42.537" 
17:48:42.587 [error] Sending find_sub batch [] 
17:48:42.587 [error] Sending find_sub_aq batch [] 
17:48:42.587 [error] batched message propagation "2020-07-03T17:48:42.587" 
17:48:52.539 [error] C1 propagation "2020-07-03T17:48:52.539" 
17:48:52.588 [error] Sending find_sub batch [] 
17:48:52.588 [error] Sending find_sub_aq batch [] 
17:48:52.588 [error] batched message propagation "2020-07-03T17:48:52.588" 
17:49:02.523 [error] C3 propagation "2020-07-03T17:49:02.523" 
17:49:02.541 [error] C1 propagation "2020-07-03T17:49:02.541" 
17:49:02.589 [error] Sending find_sub batch [] 
17:49:02.589 [error] Sending find_sub_aq batch [] 
17:49:02.589 [error] batched message propagation "2020-07-03T17:49:02.589" 
17:49:12.543 [error] C1 propagation "2020-07-03T17:49:12.543" 
17:49:12.590 [error] Sending find_sub batch [] 
17:49:12.590 [error] Sending find_sub_aq batch [] 
17:49:12.590 [error] batched message propagation "2020-07-03T17:49:12.590" 
17:49:15.842 [error] LASPVIN Received delta From='c@10.0.0.13' at TimeStamp="2020-07-03T17:49:15.842" Took=62910 microseconds DeltaVal:[{<<"key1">>,{set,1,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[],[#{what => val_gurnu}],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}}}] 
17:49:15.842 [error] Message Counters [{"Message","Tx","Rx"},{"check_tonode",0,0},{"check_tonode_ack",0,0},{"delta_ack",0,0},{"delta_send",0,1},{"find_sub",3,3},{"find_sub_aq",3,4},{"find_sub_aq_lock",0,4},{"rate_ack",5,6},{"rate_class",6,5},{"rate_refresh",0,0},{"rate_subscribe",1,2},{"rate_subscribe_ack",2,1},{"send_backend",20,0},{"sub_cancel",0,0}] 
17:49:21.058 [error] LASPVIN Received delta From='c@10.0.0.13' at TimeStamp="2020-07-03T17:49:21.586" Took=20279 microseconds DeltaVal:[{<<"key1">>,{set,1,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[#{what => val_wadhw}],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}}}] 
17:49:21.058 [error] Message Counters [{"Message","Tx","Rx"},{"check_tonode",0,0},{"check_tonode_ack",0,0},{"delta_ack",1,0},{"delta_send",0,2},{"find_sub",3,3},{"find_sub_aq",3,4},{"find_sub_aq_lock",0,4},{"rate_ack",5,6},{"rate_class",6,5},{"rate_refresh",0,0},{"rate_subscribe",1,2},{"rate_subscribe_ack",2,1},{"send_backend",21,0},{"sub_cancel",0,0}] 
17:49:22.178 [error] LASPVIN Received delta From='b@10.0.0.12' at TimeStamp="2020-07-03T17:49:22.178" Took=204 microseconds DeltaVal:[{<<"key1">>,{set,1,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[#{what => val_wadhw}],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}}}] 
17:49:22.178 [error] Message Counters [{"Message","Tx","Rx"},{"check_tonode",0,0},{"check_tonode_ack",0,0},{"delta_ack",2,0},{"delta_send",0,3},{"find_sub",3,3},{"find_sub_aq",3,4},{"find_sub_aq_lock",0,4},{"rate_ack",5,6},{"rate_class",6,5},{"rate_refresh",0,0},{"rate_subscribe",1,2},{"rate_subscribe_ack",2,1},{"send_backend",22,0},{"sub_cancel",0,0}] 
17:49:22.527 [error] C2 propagation "2020-07-03T17:49:22.527" 
17:49:22.544 [error] C1 propagation "2020-07-03T17:49:22.544" 
17:49:22.546 [error] LASPVIN Sending delta to 'c@10.0.0.13' 
17:49:22.546 [error] Id: {<<"awmap">>,{state_awmap,[state_mvregister]}} Type: {state_awmap,[state_mvregister]} Metadata: [{clock,[{<<125,77,131,56,119,66,210,129,48,185,161,155,112,188,187,57,72,201,31,86>>,4}]}] Deltas: {state_awmap,{state_mvregister,{[],{[],[]}}}} Counter:2 
17:49:22.547 [error] LASPVIN Sending delta to 'a@11.0.0.11' 
17:49:22.547 [error] Id: {<<"awmap">>,{state_awmap,[state_mvregister]}} Type: {state_awmap,[state_mvregister]} Metadata: [{clock,[{<<125,77,131,56,119,66,210,129,48,185,161,155,112,188,187,57,72,201,31,86>>,4}]}] Deltas: {state_awmap,{state_mvregister,{[{<<"key1">>,[{{{partisan_remote_reference,'c@10.0.0.13',{partisan_process_reference,"<0.209.0>"}},2},#{what => val_wadhw}}]}],{[{{partisan_remote_reference,'c@10.0.0.13',{partisan_process_reference,"<0.209.0>"}},2}],[]}}}} Counter:2 
17:49:22.605 [error] Sending find_sub batch [] 
17:49:22.605 [error] Sending find_sub_aq batch [] 
17:49:22.606 [error] batched message propagation "2020-07-03T17:49:22.605" 
17:49:25.639 [error] LASPVIN Received delta From='a@11.0.0.11' at TimeStamp="2020-07-03T17:49:25.639" Took=696 microseconds DeltaVal:[{<<"key1">>,{set,1,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[#{what => val_wadhw}],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}}}] 
17:49:25.639 [error] Message Counters [{"Message","Tx","Rx"},{"check_tonode",0,0},{"check_tonode_ack",0,0},{"delta_ack",3,2},{"delta_send",2,4},{"find_sub",3,3},{"find_sub_aq",3,4},{"find_sub_aq_lock",0,4},{"rate_ack",5,6},{"rate_class",6,5},{"rate_refresh",0,0},{"rate_subscribe",1,2},{"rate_subscribe_ack",2,1},{"send_backend",25,0},{"sub_cancel",0,0}] 
17:49:32.546 [error] C1 propagation "2020-07-03T17:49:32.546" 
17:49:32.607 [error] Sending find_sub batch [] 
17:49:32.607 [error] Sending find_sub_aq batch [] 
17:49:32.607 [error] batched message propagation "2020-07-03T17:49:32.607" 
17:49:42.548 [error] C1 propagation "2020-07-03T17:49:42.548" 
17:49:42.609 [error] Sending find_sub batch [] 
17:49:42.609 [error] Sending find_sub_aq batch [] 
17:49:42.609 [error] batched message propagation "2020-07-03T17:49:42.609" 
17:49:52.550 [error] C1 propagation "2020-07-03T17:49:52.550" 
17:49:52.611 [error] Sending find_sub batch [] 
17:49:52.611 [error] Sending find_sub_aq batch [] 
17:49:52.611 [error] batched message propagation "2020-07-03T17:49:52.611" 
17:50:02.528 [error] C2 propagation "2020-07-03T17:50:02.528" 
17:50:02.552 [error] C1 propagation "2020-07-03T17:50:02.552" 
17:50:02.612 [error] Sending find_sub batch [] 
17:50:02.612 [error] Sending find_sub_aq batch [] 
17:50:02.612 [error] batched message propagation "2020-07-03T17:50:02.612" 
17:50:12.524 [error] C3 propagation "2020-07-03T17:50:12.524" 
17:50:12.554 [error] C1 propagation "2020-07-03T17:50:12.554" 
17:50:12.614 [error] Sending find_sub batch [] 
17:50:12.614 [error] Sending find_sub_aq batch [] 
17:50:12.614 [error] batched message propagation "2020-07-03T17:50:12.614" 
17:50:22.556 [error] C1 propagation "2020-07-03T17:50:22.556" 
17:50:22.616 [error] Sending find_sub batch [] 
17:50:22.616 [error] Sending find_sub_aq batch [] 
17:50:22.616 [error] batched message propagation "2020-07-03T17:50:22.616" 
17:50:32.558 [error] C1 propagation "2020-07-03T17:50:32.558" 
17:50:32.618 [error] Sending find_sub batch [] 
17:50:32.618 [error] Sending find_sub_aq batch [] 
17:50:32.618 [error] batched message propagation "2020-07-03T17:50:32.618" 
17:50:42.530 [error] C2 propagation "2020-07-03T17:50:42.530" 
17:50:42.560 [error] C1 propagation "2020-07-03T17:50:42.560" 
17:50:42.620 [error] Sending find_sub batch [] 
17:50:42.620 [error] Sending find_sub_aq batch [] 
17:50:42.620 [error] batched message propagation "2020-07-03T17:50:42.620" 
17:50:52.562 [error] C1 propagation "2020-07-03T17:50:52.562" 
17:50:52.621 [error] Sending find_sub batch [] 
17:50:52.621 [error] Sending find_sub_aq batch [] 
17:50:52.621 [error] batched message propagation "2020-07-03T17:50:52.621" 
17:51:02.564 [error] C1 propagation "2020-07-03T17:51:02.564" 
17:51:02.623 [error] Sending find_sub batch [] 
17:51:02.623 [error] Sending find_sub_aq batch [] 
17:51:02.623 [error] batched message propagation "2020-07-03T17:51:02.623" 
17:51:12.566 [error] C1 propagation "2020-07-03T17:51:12.566" 
17:51:12.624 [error] Sending find_sub batch [] 
17:51:12.624 [error] Sending find_sub_aq batch [] 
17:51:12.625 [error] batched message propagation "2020-07-03T17:51:12.624" 
